{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/ner_dataset.csv\", encoding = 'unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(0, len(df) - 1):\n",
    "#     if pd.isnull(df.loc[i + 1, \"Sentence #\"]):\n",
    "#         df.loc[i + 1, \"Sentence #\"] = df.loc[i, \"Sentence #\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_number_values = []\n",
    "# for i in np.arange(0, len(df)):\n",
    "#     sentence_number_values.append(int(df.loc[i, \"Sentence #\"].split()[1]))\n",
    "# df[\"Sentence # Val\"] = sentence_number_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_train_sentences = math.floor(47959 * .8)\n",
    "# train_sentences_numbers = set(np.random.choice(47959, number_of_train_sentences, replace = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentences_numbers = set(df[\"Sentence # Val\"]) - train_sentences_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns = [\"Sentence #\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = df.loc[df[\"Sentence # Val\"].isin(train_sentences_numbers)]\n",
    "# test_df = df.loc[df[\"Sentence # Val\"].isin(test_sentences_numbers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"./data/ner_train_dataset.csv\", index = False)\n",
    "# test_df.to_csv(\"./data/ner_test_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Test Datasets After Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/ner_train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"./data/ner_test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence # Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837951</th>\n",
       "      <td>rockets</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>47958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837952</th>\n",
       "      <td>exploded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>47958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837953</th>\n",
       "      <td>upon</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>47958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837954</th>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>47958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837955</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>47958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837956 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word  POS Tag  Sentence # Val\n",
       "0           Thousands  NNS   O               1\n",
       "1                  of   IN   O               1\n",
       "2       demonstrators  NNS   O               1\n",
       "3                have  VBP   O               1\n",
       "4             marched  VBN   O               1\n",
       "...               ...  ...  ..             ...\n",
       "837951        rockets  NNS   O           47958\n",
       "837952       exploded  VBD   O           47958\n",
       "837953           upon   IN   O           47958\n",
       "837954         impact   NN   O           47958\n",
       "837955              .    .   O           47958\n",
       "\n",
       "[837956 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 of 837956 processed.\n",
      "Row 1000 of 837956 processed.\n",
      "Row 2000 of 837956 processed.\n",
      "Row 3000 of 837956 processed.\n",
      "Row 4000 of 837956 processed.\n",
      "Row 5000 of 837956 processed.\n",
      "Row 6000 of 837956 processed.\n",
      "Row 7000 of 837956 processed.\n",
      "Row 8000 of 837956 processed.\n",
      "Row 9000 of 837956 processed.\n",
      "Row 10000 of 837956 processed.\n",
      "Row 11000 of 837956 processed.\n",
      "Row 12000 of 837956 processed.\n",
      "Row 13000 of 837956 processed.\n",
      "Row 14000 of 837956 processed.\n",
      "Row 15000 of 837956 processed.\n",
      "Row 16000 of 837956 processed.\n",
      "Row 17000 of 837956 processed.\n",
      "Row 18000 of 837956 processed.\n",
      "Row 19000 of 837956 processed.\n",
      "Row 20000 of 837956 processed.\n",
      "Row 21000 of 837956 processed.\n",
      "Row 22000 of 837956 processed.\n",
      "Row 23000 of 837956 processed.\n",
      "Row 24000 of 837956 processed.\n",
      "Row 25000 of 837956 processed.\n",
      "Row 26000 of 837956 processed.\n",
      "Row 27000 of 837956 processed.\n",
      "Row 28000 of 837956 processed.\n",
      "Row 29000 of 837956 processed.\n",
      "Row 30000 of 837956 processed.\n",
      "Row 31000 of 837956 processed.\n",
      "Row 32000 of 837956 processed.\n",
      "Row 33000 of 837956 processed.\n",
      "Row 34000 of 837956 processed.\n",
      "Row 35000 of 837956 processed.\n",
      "Row 36000 of 837956 processed.\n",
      "Row 37000 of 837956 processed.\n",
      "Row 38000 of 837956 processed.\n",
      "Row 39000 of 837956 processed.\n",
      "Row 40000 of 837956 processed.\n",
      "Row 41000 of 837956 processed.\n",
      "Row 42000 of 837956 processed.\n",
      "Row 43000 of 837956 processed.\n",
      "Row 44000 of 837956 processed.\n",
      "Row 45000 of 837956 processed.\n",
      "Row 46000 of 837956 processed.\n",
      "Row 47000 of 837956 processed.\n",
      "Row 48000 of 837956 processed.\n",
      "Row 49000 of 837956 processed.\n",
      "Row 50000 of 837956 processed.\n",
      "Row 51000 of 837956 processed.\n",
      "Row 52000 of 837956 processed.\n",
      "Row 53000 of 837956 processed.\n",
      "Row 54000 of 837956 processed.\n",
      "Row 55000 of 837956 processed.\n",
      "Row 56000 of 837956 processed.\n",
      "Row 57000 of 837956 processed.\n",
      "Row 58000 of 837956 processed.\n",
      "Row 59000 of 837956 processed.\n",
      "Row 60000 of 837956 processed.\n",
      "Row 61000 of 837956 processed.\n",
      "Row 62000 of 837956 processed.\n",
      "Row 63000 of 837956 processed.\n",
      "Row 64000 of 837956 processed.\n",
      "Row 65000 of 837956 processed.\n",
      "Row 66000 of 837956 processed.\n",
      "Row 67000 of 837956 processed.\n",
      "Row 68000 of 837956 processed.\n",
      "Row 69000 of 837956 processed.\n",
      "Row 70000 of 837956 processed.\n",
      "Row 71000 of 837956 processed.\n",
      "Row 72000 of 837956 processed.\n",
      "Row 73000 of 837956 processed.\n",
      "Row 74000 of 837956 processed.\n",
      "Row 75000 of 837956 processed.\n",
      "Row 76000 of 837956 processed.\n",
      "Row 77000 of 837956 processed.\n",
      "Row 78000 of 837956 processed.\n",
      "Row 79000 of 837956 processed.\n",
      "Row 80000 of 837956 processed.\n",
      "Row 81000 of 837956 processed.\n",
      "Row 82000 of 837956 processed.\n",
      "Row 83000 of 837956 processed.\n",
      "Row 84000 of 837956 processed.\n",
      "Row 85000 of 837956 processed.\n",
      "Row 86000 of 837956 processed.\n",
      "Row 87000 of 837956 processed.\n",
      "Row 88000 of 837956 processed.\n",
      "Row 89000 of 837956 processed.\n",
      "Row 90000 of 837956 processed.\n",
      "Row 91000 of 837956 processed.\n",
      "Row 92000 of 837956 processed.\n",
      "Row 93000 of 837956 processed.\n",
      "Row 94000 of 837956 processed.\n",
      "Row 95000 of 837956 processed.\n",
      "Row 96000 of 837956 processed.\n",
      "Row 97000 of 837956 processed.\n",
      "Row 98000 of 837956 processed.\n",
      "Row 99000 of 837956 processed.\n",
      "Row 100000 of 837956 processed.\n",
      "Row 101000 of 837956 processed.\n",
      "Row 102000 of 837956 processed.\n",
      "Row 103000 of 837956 processed.\n",
      "Row 104000 of 837956 processed.\n",
      "Row 105000 of 837956 processed.\n",
      "Row 106000 of 837956 processed.\n",
      "Row 107000 of 837956 processed.\n",
      "Row 108000 of 837956 processed.\n",
      "Row 109000 of 837956 processed.\n",
      "Row 110000 of 837956 processed.\n",
      "Row 111000 of 837956 processed.\n",
      "Row 112000 of 837956 processed.\n",
      "Row 113000 of 837956 processed.\n",
      "Row 114000 of 837956 processed.\n",
      "Row 115000 of 837956 processed.\n",
      "Row 116000 of 837956 processed.\n",
      "Row 117000 of 837956 processed.\n",
      "Row 118000 of 837956 processed.\n",
      "Row 119000 of 837956 processed.\n",
      "Row 120000 of 837956 processed.\n",
      "Row 121000 of 837956 processed.\n",
      "Row 122000 of 837956 processed.\n",
      "Row 123000 of 837956 processed.\n",
      "Row 124000 of 837956 processed.\n",
      "Row 125000 of 837956 processed.\n",
      "Row 126000 of 837956 processed.\n",
      "Row 127000 of 837956 processed.\n",
      "Row 128000 of 837956 processed.\n",
      "Row 129000 of 837956 processed.\n",
      "Row 130000 of 837956 processed.\n",
      "Row 131000 of 837956 processed.\n",
      "Row 132000 of 837956 processed.\n",
      "Row 133000 of 837956 processed.\n",
      "Row 134000 of 837956 processed.\n",
      "Row 135000 of 837956 processed.\n",
      "Row 136000 of 837956 processed.\n",
      "Row 137000 of 837956 processed.\n",
      "Row 138000 of 837956 processed.\n",
      "Row 139000 of 837956 processed.\n",
      "Row 140000 of 837956 processed.\n",
      "Row 141000 of 837956 processed.\n",
      "Row 142000 of 837956 processed.\n",
      "Row 143000 of 837956 processed.\n",
      "Row 144000 of 837956 processed.\n",
      "Row 145000 of 837956 processed.\n",
      "Row 146000 of 837956 processed.\n",
      "Row 147000 of 837956 processed.\n",
      "Row 148000 of 837956 processed.\n",
      "Row 149000 of 837956 processed.\n",
      "Row 150000 of 837956 processed.\n",
      "Row 151000 of 837956 processed.\n",
      "Row 152000 of 837956 processed.\n",
      "Row 153000 of 837956 processed.\n",
      "Row 154000 of 837956 processed.\n",
      "Row 155000 of 837956 processed.\n",
      "Row 156000 of 837956 processed.\n",
      "Row 157000 of 837956 processed.\n",
      "Row 158000 of 837956 processed.\n",
      "Row 159000 of 837956 processed.\n",
      "Row 160000 of 837956 processed.\n",
      "Row 161000 of 837956 processed.\n",
      "Row 162000 of 837956 processed.\n",
      "Row 163000 of 837956 processed.\n",
      "Row 164000 of 837956 processed.\n",
      "Row 165000 of 837956 processed.\n",
      "Row 166000 of 837956 processed.\n",
      "Row 167000 of 837956 processed.\n",
      "Row 168000 of 837956 processed.\n",
      "Row 169000 of 837956 processed.\n",
      "Row 170000 of 837956 processed.\n",
      "Row 171000 of 837956 processed.\n",
      "Row 172000 of 837956 processed.\n",
      "Row 173000 of 837956 processed.\n",
      "Row 174000 of 837956 processed.\n",
      "Row 175000 of 837956 processed.\n",
      "Row 176000 of 837956 processed.\n",
      "Row 177000 of 837956 processed.\n",
      "Row 178000 of 837956 processed.\n",
      "Row 179000 of 837956 processed.\n",
      "Row 180000 of 837956 processed.\n",
      "Row 181000 of 837956 processed.\n",
      "Row 182000 of 837956 processed.\n",
      "Row 183000 of 837956 processed.\n",
      "Row 184000 of 837956 processed.\n",
      "Row 185000 of 837956 processed.\n",
      "Row 186000 of 837956 processed.\n",
      "Row 187000 of 837956 processed.\n",
      "Row 188000 of 837956 processed.\n",
      "Row 189000 of 837956 processed.\n",
      "Row 190000 of 837956 processed.\n",
      "Row 191000 of 837956 processed.\n",
      "Row 192000 of 837956 processed.\n",
      "Row 193000 of 837956 processed.\n",
      "Row 194000 of 837956 processed.\n",
      "Row 195000 of 837956 processed.\n",
      "Row 196000 of 837956 processed.\n",
      "Row 197000 of 837956 processed.\n",
      "Row 198000 of 837956 processed.\n",
      "Row 199000 of 837956 processed.\n",
      "Row 200000 of 837956 processed.\n",
      "Row 201000 of 837956 processed.\n",
      "Row 202000 of 837956 processed.\n",
      "Row 203000 of 837956 processed.\n",
      "Row 204000 of 837956 processed.\n",
      "Row 205000 of 837956 processed.\n",
      "Row 206000 of 837956 processed.\n",
      "Row 207000 of 837956 processed.\n",
      "Row 208000 of 837956 processed.\n",
      "Row 209000 of 837956 processed.\n",
      "Row 210000 of 837956 processed.\n",
      "Row 211000 of 837956 processed.\n",
      "Row 212000 of 837956 processed.\n",
      "Row 213000 of 837956 processed.\n",
      "Row 214000 of 837956 processed.\n",
      "Row 215000 of 837956 processed.\n",
      "Row 216000 of 837956 processed.\n",
      "Row 217000 of 837956 processed.\n",
      "Row 218000 of 837956 processed.\n",
      "Row 219000 of 837956 processed.\n",
      "Row 220000 of 837956 processed.\n",
      "Row 221000 of 837956 processed.\n",
      "Row 222000 of 837956 processed.\n",
      "Row 223000 of 837956 processed.\n",
      "Row 224000 of 837956 processed.\n",
      "Row 225000 of 837956 processed.\n",
      "Row 226000 of 837956 processed.\n",
      "Row 227000 of 837956 processed.\n",
      "Row 228000 of 837956 processed.\n",
      "Row 229000 of 837956 processed.\n",
      "Row 230000 of 837956 processed.\n",
      "Row 231000 of 837956 processed.\n",
      "Row 232000 of 837956 processed.\n",
      "Row 233000 of 837956 processed.\n",
      "Row 234000 of 837956 processed.\n",
      "Row 235000 of 837956 processed.\n",
      "Row 236000 of 837956 processed.\n",
      "Row 237000 of 837956 processed.\n",
      "Row 238000 of 837956 processed.\n",
      "Row 239000 of 837956 processed.\n",
      "Row 240000 of 837956 processed.\n",
      "Row 241000 of 837956 processed.\n",
      "Row 242000 of 837956 processed.\n",
      "Row 243000 of 837956 processed.\n",
      "Row 244000 of 837956 processed.\n",
      "Row 245000 of 837956 processed.\n",
      "Row 246000 of 837956 processed.\n",
      "Row 247000 of 837956 processed.\n",
      "Row 248000 of 837956 processed.\n",
      "Row 249000 of 837956 processed.\n",
      "Row 250000 of 837956 processed.\n",
      "Row 251000 of 837956 processed.\n",
      "Row 252000 of 837956 processed.\n",
      "Row 253000 of 837956 processed.\n",
      "Row 254000 of 837956 processed.\n",
      "Row 255000 of 837956 processed.\n",
      "Row 256000 of 837956 processed.\n",
      "Row 257000 of 837956 processed.\n",
      "Row 258000 of 837956 processed.\n",
      "Row 259000 of 837956 processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 260000 of 837956 processed.\n",
      "Row 261000 of 837956 processed.\n",
      "Row 262000 of 837956 processed.\n",
      "Row 263000 of 837956 processed.\n",
      "Row 264000 of 837956 processed.\n",
      "Row 265000 of 837956 processed.\n",
      "Row 266000 of 837956 processed.\n",
      "Row 267000 of 837956 processed.\n",
      "Row 268000 of 837956 processed.\n",
      "Row 269000 of 837956 processed.\n",
      "Row 270000 of 837956 processed.\n",
      "Row 271000 of 837956 processed.\n",
      "Row 272000 of 837956 processed.\n",
      "Row 273000 of 837956 processed.\n",
      "Row 274000 of 837956 processed.\n",
      "Row 275000 of 837956 processed.\n",
      "Row 276000 of 837956 processed.\n",
      "Row 277000 of 837956 processed.\n",
      "Row 278000 of 837956 processed.\n",
      "Row 279000 of 837956 processed.\n",
      "Row 280000 of 837956 processed.\n",
      "Row 281000 of 837956 processed.\n",
      "Row 282000 of 837956 processed.\n",
      "Row 283000 of 837956 processed.\n",
      "Row 284000 of 837956 processed.\n",
      "Row 285000 of 837956 processed.\n",
      "Row 286000 of 837956 processed.\n",
      "Row 287000 of 837956 processed.\n",
      "Row 288000 of 837956 processed.\n",
      "Row 289000 of 837956 processed.\n",
      "Row 290000 of 837956 processed.\n",
      "Row 291000 of 837956 processed.\n",
      "Row 292000 of 837956 processed.\n",
      "Row 293000 of 837956 processed.\n",
      "Row 294000 of 837956 processed.\n",
      "Row 295000 of 837956 processed.\n",
      "Row 296000 of 837956 processed.\n",
      "Row 297000 of 837956 processed.\n",
      "Row 298000 of 837956 processed.\n",
      "Row 299000 of 837956 processed.\n",
      "Row 300000 of 837956 processed.\n",
      "Row 301000 of 837956 processed.\n",
      "Row 302000 of 837956 processed.\n",
      "Row 303000 of 837956 processed.\n",
      "Row 304000 of 837956 processed.\n",
      "Row 305000 of 837956 processed.\n",
      "Row 306000 of 837956 processed.\n",
      "Row 307000 of 837956 processed.\n",
      "Row 308000 of 837956 processed.\n",
      "Row 309000 of 837956 processed.\n",
      "Row 310000 of 837956 processed.\n",
      "Row 311000 of 837956 processed.\n",
      "Row 312000 of 837956 processed.\n",
      "Row 313000 of 837956 processed.\n",
      "Row 314000 of 837956 processed.\n",
      "Row 315000 of 837956 processed.\n",
      "Row 316000 of 837956 processed.\n",
      "Row 317000 of 837956 processed.\n",
      "Row 318000 of 837956 processed.\n",
      "Row 319000 of 837956 processed.\n",
      "Row 320000 of 837956 processed.\n",
      "Row 321000 of 837956 processed.\n",
      "Row 322000 of 837956 processed.\n",
      "Row 323000 of 837956 processed.\n",
      "Row 324000 of 837956 processed.\n",
      "Row 325000 of 837956 processed.\n",
      "Row 326000 of 837956 processed.\n",
      "Row 327000 of 837956 processed.\n",
      "Row 328000 of 837956 processed.\n",
      "Row 329000 of 837956 processed.\n",
      "Row 330000 of 837956 processed.\n",
      "Row 331000 of 837956 processed.\n",
      "Row 332000 of 837956 processed.\n",
      "Row 333000 of 837956 processed.\n",
      "Row 334000 of 837956 processed.\n",
      "Row 335000 of 837956 processed.\n",
      "Row 336000 of 837956 processed.\n",
      "Row 337000 of 837956 processed.\n",
      "Row 338000 of 837956 processed.\n",
      "Row 339000 of 837956 processed.\n",
      "Row 340000 of 837956 processed.\n",
      "Row 341000 of 837956 processed.\n",
      "Row 342000 of 837956 processed.\n",
      "Row 343000 of 837956 processed.\n",
      "Row 344000 of 837956 processed.\n",
      "Row 345000 of 837956 processed.\n",
      "Row 346000 of 837956 processed.\n",
      "Row 347000 of 837956 processed.\n",
      "Row 348000 of 837956 processed.\n",
      "Row 349000 of 837956 processed.\n",
      "Row 350000 of 837956 processed.\n",
      "Row 351000 of 837956 processed.\n",
      "Row 352000 of 837956 processed.\n",
      "Row 353000 of 837956 processed.\n",
      "Row 354000 of 837956 processed.\n",
      "Row 355000 of 837956 processed.\n",
      "Row 356000 of 837956 processed.\n",
      "Row 357000 of 837956 processed.\n",
      "Row 358000 of 837956 processed.\n",
      "Row 359000 of 837956 processed.\n",
      "Row 360000 of 837956 processed.\n",
      "Row 361000 of 837956 processed.\n",
      "Row 362000 of 837956 processed.\n",
      "Row 363000 of 837956 processed.\n",
      "Row 364000 of 837956 processed.\n",
      "Row 365000 of 837956 processed.\n",
      "Row 366000 of 837956 processed.\n",
      "Row 367000 of 837956 processed.\n",
      "Row 368000 of 837956 processed.\n",
      "Row 369000 of 837956 processed.\n",
      "Row 370000 of 837956 processed.\n",
      "Row 371000 of 837956 processed.\n",
      "Row 372000 of 837956 processed.\n",
      "Row 373000 of 837956 processed.\n",
      "Row 374000 of 837956 processed.\n",
      "Row 375000 of 837956 processed.\n",
      "Row 376000 of 837956 processed.\n",
      "Row 377000 of 837956 processed.\n",
      "Row 378000 of 837956 processed.\n",
      "Row 379000 of 837956 processed.\n",
      "Row 380000 of 837956 processed.\n",
      "Row 381000 of 837956 processed.\n",
      "Row 382000 of 837956 processed.\n",
      "Row 383000 of 837956 processed.\n",
      "Row 384000 of 837956 processed.\n",
      "Row 385000 of 837956 processed.\n",
      "Row 386000 of 837956 processed.\n",
      "Row 387000 of 837956 processed.\n",
      "Row 388000 of 837956 processed.\n",
      "Row 389000 of 837956 processed.\n",
      "Row 390000 of 837956 processed.\n",
      "Row 391000 of 837956 processed.\n",
      "Row 392000 of 837956 processed.\n",
      "Row 393000 of 837956 processed.\n",
      "Row 394000 of 837956 processed.\n",
      "Row 395000 of 837956 processed.\n",
      "Row 396000 of 837956 processed.\n",
      "Row 397000 of 837956 processed.\n",
      "Row 398000 of 837956 processed.\n",
      "Row 399000 of 837956 processed.\n",
      "Row 400000 of 837956 processed.\n",
      "Row 401000 of 837956 processed.\n",
      "Row 402000 of 837956 processed.\n",
      "Row 403000 of 837956 processed.\n",
      "Row 404000 of 837956 processed.\n",
      "Row 405000 of 837956 processed.\n",
      "Row 406000 of 837956 processed.\n",
      "Row 407000 of 837956 processed.\n",
      "Row 408000 of 837956 processed.\n",
      "Row 409000 of 837956 processed.\n",
      "Row 410000 of 837956 processed.\n",
      "Row 411000 of 837956 processed.\n",
      "Row 412000 of 837956 processed.\n",
      "Row 413000 of 837956 processed.\n",
      "Row 414000 of 837956 processed.\n",
      "Row 415000 of 837956 processed.\n",
      "Row 416000 of 837956 processed.\n",
      "Row 417000 of 837956 processed.\n",
      "Row 418000 of 837956 processed.\n",
      "Row 419000 of 837956 processed.\n",
      "Row 420000 of 837956 processed.\n",
      "Row 421000 of 837956 processed.\n",
      "Row 422000 of 837956 processed.\n",
      "Row 423000 of 837956 processed.\n",
      "Row 424000 of 837956 processed.\n",
      "Row 425000 of 837956 processed.\n",
      "Row 426000 of 837956 processed.\n",
      "Row 427000 of 837956 processed.\n",
      "Row 428000 of 837956 processed.\n",
      "Row 429000 of 837956 processed.\n",
      "Row 430000 of 837956 processed.\n",
      "Row 431000 of 837956 processed.\n",
      "Row 432000 of 837956 processed.\n",
      "Row 433000 of 837956 processed.\n",
      "Row 434000 of 837956 processed.\n",
      "Row 435000 of 837956 processed.\n",
      "Row 436000 of 837956 processed.\n",
      "Row 437000 of 837956 processed.\n",
      "Row 438000 of 837956 processed.\n",
      "Row 439000 of 837956 processed.\n",
      "Row 440000 of 837956 processed.\n",
      "Row 441000 of 837956 processed.\n",
      "Row 442000 of 837956 processed.\n",
      "Row 443000 of 837956 processed.\n",
      "Row 444000 of 837956 processed.\n",
      "Row 445000 of 837956 processed.\n",
      "Row 446000 of 837956 processed.\n",
      "Row 447000 of 837956 processed.\n",
      "Row 448000 of 837956 processed.\n",
      "Row 449000 of 837956 processed.\n",
      "Row 450000 of 837956 processed.\n",
      "Row 451000 of 837956 processed.\n",
      "Row 452000 of 837956 processed.\n",
      "Row 453000 of 837956 processed.\n",
      "Row 454000 of 837956 processed.\n",
      "Row 455000 of 837956 processed.\n",
      "Row 456000 of 837956 processed.\n",
      "Row 457000 of 837956 processed.\n",
      "Row 458000 of 837956 processed.\n",
      "Row 459000 of 837956 processed.\n",
      "Row 460000 of 837956 processed.\n",
      "Row 461000 of 837956 processed.\n",
      "Row 462000 of 837956 processed.\n",
      "Row 463000 of 837956 processed.\n",
      "Row 464000 of 837956 processed.\n",
      "Row 465000 of 837956 processed.\n",
      "Row 466000 of 837956 processed.\n",
      "Row 467000 of 837956 processed.\n",
      "Row 468000 of 837956 processed.\n",
      "Row 469000 of 837956 processed.\n",
      "Row 470000 of 837956 processed.\n",
      "Row 471000 of 837956 processed.\n",
      "Row 472000 of 837956 processed.\n",
      "Row 473000 of 837956 processed.\n",
      "Row 474000 of 837956 processed.\n",
      "Row 475000 of 837956 processed.\n",
      "Row 476000 of 837956 processed.\n",
      "Row 477000 of 837956 processed.\n",
      "Row 478000 of 837956 processed.\n",
      "Row 479000 of 837956 processed.\n",
      "Row 480000 of 837956 processed.\n",
      "Row 481000 of 837956 processed.\n",
      "Row 482000 of 837956 processed.\n",
      "Row 483000 of 837956 processed.\n",
      "Row 484000 of 837956 processed.\n",
      "Row 485000 of 837956 processed.\n",
      "Row 486000 of 837956 processed.\n",
      "Row 487000 of 837956 processed.\n",
      "Row 488000 of 837956 processed.\n",
      "Row 489000 of 837956 processed.\n",
      "Row 490000 of 837956 processed.\n",
      "Row 491000 of 837956 processed.\n",
      "Row 492000 of 837956 processed.\n",
      "Row 493000 of 837956 processed.\n",
      "Row 494000 of 837956 processed.\n",
      "Row 495000 of 837956 processed.\n",
      "Row 496000 of 837956 processed.\n",
      "Row 497000 of 837956 processed.\n",
      "Row 498000 of 837956 processed.\n",
      "Row 499000 of 837956 processed.\n",
      "Row 500000 of 837956 processed.\n",
      "Row 501000 of 837956 processed.\n",
      "Row 502000 of 837956 processed.\n",
      "Row 503000 of 837956 processed.\n",
      "Row 504000 of 837956 processed.\n",
      "Row 505000 of 837956 processed.\n",
      "Row 506000 of 837956 processed.\n",
      "Row 507000 of 837956 processed.\n",
      "Row 508000 of 837956 processed.\n",
      "Row 509000 of 837956 processed.\n",
      "Row 510000 of 837956 processed.\n",
      "Row 511000 of 837956 processed.\n",
      "Row 512000 of 837956 processed.\n",
      "Row 513000 of 837956 processed.\n",
      "Row 514000 of 837956 processed.\n",
      "Row 515000 of 837956 processed.\n",
      "Row 516000 of 837956 processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 517000 of 837956 processed.\n",
      "Row 518000 of 837956 processed.\n",
      "Row 519000 of 837956 processed.\n",
      "Row 520000 of 837956 processed.\n",
      "Row 521000 of 837956 processed.\n",
      "Row 522000 of 837956 processed.\n",
      "Row 523000 of 837956 processed.\n",
      "Row 524000 of 837956 processed.\n",
      "Row 525000 of 837956 processed.\n",
      "Row 526000 of 837956 processed.\n",
      "Row 527000 of 837956 processed.\n",
      "Row 528000 of 837956 processed.\n",
      "Row 529000 of 837956 processed.\n",
      "Row 530000 of 837956 processed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9553f127cec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"'s\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Row {i} of {len(train_df)} processed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1763\u001b[0m                 \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m                     \u001b[0misetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in np.arange(0, len(train_df) - 1):\n",
    "    if train_df.loc[i + 1, \"Word\"] == \"'s\":\n",
    "        train_df.loc[i, \"Word\"] = train_df.loc[i, \"Word\"] + train_df.loc[i + 1, \"Word\"]\n",
    "        train_df.loc[i + 1, \"Word\"] = \"*\"\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Row {i} of {len(train_df)} processed.\")\n",
    "train_df.drop(index = train_df[train_df[\"Word\"] == \"*\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(index = train_df[train_df[\"Word\"] == \",\"].index, inplace = True)\n",
    "train_df.drop(index = train_df[train_df[\"Word\"] == \".\"].index, inplace = True)\n",
    "train_df.drop(index = train_df[train_df[\"Word\"] == \":\"].index, inplace = True)\n",
    "train_df.drop(index = train_df[train_df[\"Word\"] == \";\"].index, inplace = True)\n",
    "train_df.drop(index = train_df[train_df[\"Word\"] == \"\\\"\"].index, inplace = True)\n",
    "\n",
    "train_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(test_df) - 1):\n",
    "    if test_df.loc[i + 1, \"Word\"] == \"'s\":\n",
    "        test_df.loc[i, \"Word\"] = test_df.loc[i, \"Word\"] + test_df.loc[i + 1, \"Word\"]\n",
    "        test_df.loc[i + 1, \"Word\"] = \"*\"\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Row {i} of {len(test_df)} processed.\")\n",
    "test_df.drop(index = test_df[test_df[\"Word\"] == \"*\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(index = test_df[test_df[\"Word\"] == \",\"].index, inplace = True)\n",
    "test_df.drop(index = test_df[test_df[\"Word\"] == \".\"].index, inplace = True)\n",
    "test_df.drop(index = test_df[test_df[\"Word\"] == \":\"].index, inplace = True)\n",
    "test_df.drop(index = test_df[test_df[\"Word\"] == \";\"].index, inplace = True)\n",
    "test_df.drop(index = test_df[test_df[\"Word\"] == \"\\\"\"].index, inplace = True)\n",
    "\n",
    "test_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"CHU\"] = [\"O\"] * len(train_df)\n",
    "test_df[\"CHU\"] = [\"O\"] * len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns = {\"Tag\": \"NER\"}, inplace = True)\n",
    "for i in np.arange(0, len(train_df)):\n",
    "    if \"-\" in train_df.loc[i, \"NER\"]:\n",
    "        train_df.loc[i, \"CHU\"] = train_df.loc[i, \"NER\"].split(\"-\")[0]\n",
    "        train_df.loc[i, \"NER\"] = train_df.loc[i, \"NER\"].split(\"-\")[1]\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Row {i} of {len(train_df)} processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.rename(columns = {\"Tag\": \"NER\"}, inplace = True)\n",
    "for i in np.arange(0, len(test_df)):\n",
    "    if \"-\" in test_df.loc[i, \"NER\"]:\n",
    "        test_df.loc[i, \"CHU\"] = test_df.loc[i, \"NER\"].split(\"-\")[0]\n",
    "        test_df.loc[i, \"NER\"] = test_df.loc[i, \"NER\"].split(\"-\")[1]\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Row {i} of {len(test_df)} processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Parts of Speech, Named Entity Recognition Tags, and Chunking Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined = pd.DataFrame()\n",
    "train_combined[\"Word\"] = train_df.groupby(\"Sentence # Val\")[\"Word\"].apply(list)\n",
    "train_combined[\"Word\"] = [' '.join(i) for i in train_combined[\"Word\"]]\n",
    "train_combined[\"POS\"] = train_df.groupby(\"Sentence # Val\")[\"POS\"].apply(list)\n",
    "train_combined[\"NER\"] = train_df.groupby(\"Sentence # Val\")[\"NER\"].apply(list)\n",
    "train_combined[\"CHU\"] = train_df.groupby(\"Sentence # Val\")[\"CHU\"].apply(list)\n",
    "train_combined.reset_index(inplace = True)\n",
    "train_df = train_combined\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = pd.DataFrame()\n",
    "test_combined[\"Word\"] = test_df.groupby(\"Sentence # Val\")[\"Word\"].apply(list)\n",
    "test_combined[\"Word\"] = [' '.join(i) for i in test_combined[\"Word\"]]\n",
    "test_combined[\"POS\"] = test_df.groupby(\"Sentence # Val\")[\"POS\"].apply(list)\n",
    "test_combined[\"NER\"] = test_df.groupby(\"Sentence # Val\")[\"NER\"].apply(list)\n",
    "test_combined[\"CHU\"] = test_df.groupby(\"Sentence # Val\")[\"CHU\"].apply(list)\n",
    "test_combined.reset_index(inplace = True)\n",
    "test_df = test_combined\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(train_df)):\n",
    "    sentence_length = len(train_df.loc[i, \"POS\"])\n",
    "    for j in np.arange(sentence_length, 105):\n",
    "        train_df.loc[i, \"POS\"].append('*')\n",
    "for i in np.arange(0, len(train_df)):\n",
    "    sentence_length = len(train_df.loc[i, \"NER\"])\n",
    "    for j in np.arange(sentence_length, 105):\n",
    "        train_df.loc[i, \"NER\"].append('*')  \n",
    "for i in np.arange(0, len(train_df)):\n",
    "    sentence_length = len(train_df.loc[i, \"CHU\"])\n",
    "    for j in np.arange(sentence_length, 105):\n",
    "        train_df.loc[i, \"CHU\"].append('*')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(test_df)):\n",
    "    sentence_length = len(test_df.loc[i, \"POS\"])\n",
    "    for j in np.arange(sentence_length, 105):\n",
    "        test_df.loc[i, \"POS\"].append('*')\n",
    "for i in np.arange(0, len(test_df)):\n",
    "    sentence_length = len(test_df.loc[i, \"NER\"])\n",
    "    for j in np.arange(sentence_length, 105):\n",
    "        test_df.loc[i, \"NER\"].append('*')\n",
    "for i in np.arange(0, len(test_df)):\n",
    "    sentence_length = len(test_df.loc[i, \"CHU\"])\n",
    "    for j in np.arange(sentence_length, 105):\n",
    "        test_df.loc[i, \"CHU\"].append('*')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pos = []\n",
    "for i in np.arange(0, len(train_df)):\n",
    "    for i in train_df.loc[i, \"POS\"]:\n",
    "        training_pos.append(i)\n",
    "        \n",
    "le_pos = preprocessing.LabelEncoder()\n",
    "le_pos.fit(training_pos)\n",
    "\n",
    "encoded_pos_train = train_df[\"POS\"].apply(lambda x: le_pos.transform(x))\n",
    "train_df[\"POS\"] = encoded_pos_train\n",
    "encoded_pos_test = test_df[\"POS\"].apply(lambda x: le_pos.transform(x))\n",
    "test_df[\"POS\"] = encoded_pos_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tag = []\n",
    "for i in np.arange(0, len(train_df)):\n",
    "    for i in train_df.loc[i, \"NER\"]:\n",
    "        training_tag.append(i)\n",
    "        \n",
    "le_ner = preprocessing.LabelEncoder()\n",
    "le_ner.fit(training_tag)\n",
    "\n",
    "encoded_tag_train = train_df[\"NER\"].apply(lambda x: le_ner.transform(x))\n",
    "train_df[\"NER\"] = encoded_tag_train\n",
    "encoded_tag_test = test_df[\"NER\"].apply(lambda x: le_ner.transform(x))\n",
    "test_df[\"NER\"] = encoded_tag_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_chu = []\n",
    "for i in np.arange(0, len(train_df)):\n",
    "    for i in train_df.loc[i, \"CHU\"]:\n",
    "        training_chu.append(i)\n",
    "        \n",
    "le_chu = preprocessing.LabelEncoder()\n",
    "le_chu.fit(training_chu)\n",
    "\n",
    "encoded_chu_train = train_df[\"CHU\"].apply(lambda x: le_chu.transform(x))\n",
    "train_df[\"CHU\"] = encoded_chu_train\n",
    "encoded_chu_test = test_df[\"CHU\"].apply(lambda x: le_chu.transform(x))\n",
    "test_df[\"CHU\"] = encoded_chu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocabulary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_words = len(set(df[\"Word\"]))\n",
    "train_samples = train_df[\"Word\"]\n",
    "test_samples = test_df[\"Word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens = None, output_sequence_length = 105)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe vectors\n",
    "glove_dir = './data/'\n",
    "path_to_glove_file = os.path.join(glove_dir, 'glove.6B.200d.txt')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit = 1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep = \" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare Embedding Matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be zeroes.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer = keras.initializers.Constant(embedding_matrix),\n",
    "    trainable = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_input = keras.Input(shape = (None, ), dtype = \"int64\", name = 'sentence_input')\n",
    "embedded_sentence = embedding_layer(sentence_input)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(400, return_sequences = True, dropout = 0.50, recurrent_dropout = 0.25, name = \"LSTM_1\"), name = \"bi_1\")(embedded_sentence)\n",
    "\n",
    "pos_branch = layers.TimeDistributed(layers.Dense(len(le_pos.classes_), activation = 'softmax', name = \"pos_dense\"), name = 'pos_output')(x)\n",
    "ner_branch = layers.TimeDistributed(layers.Dense(len(le_ner.classes_), activation = 'softmax', name = \"ner_dense\"), name = 'ner_output')(x)\n",
    "chu_branch = layers.TimeDistributed(layers.Dense(len(le_chu.classes_), activation = 'softmax', name = \"chu_dense\"), name = 'chu_output')(x)\n",
    "\n",
    "model = keras.Model(inputs = sentence_input, outputs = [pos_branch, ner_branch, chu_branch], name = \"model_1\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)\n",
    "\n",
    "y_train_pos_array = to_categorical(train_df[\"POS\"], len(le_pos.classes_))\n",
    "y_test_pos_array = to_categorical(test_df[\"POS\"], len(le_pos.classes_))\n",
    "\n",
    "y_train_ner_array = to_categorical(train_df[\"NER\"], len(le_ner.classes_))\n",
    "y_test_ner_array = to_categorical(test_df[\"NER\"], len(le_ner.classes_))\n",
    "\n",
    "y_train_chu_array = to_categorical(train_df[\"CHU\"], len(le_chu.classes_))\n",
    "y_test_chu_array = to_categorical(test_df[\"CHU\"], len(le_chu.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples]))\n",
    "x_test = vectorizer(np.array([[s] for s in test_samples]))\n",
    "\n",
    "y_train_pos = tf.convert_to_tensor(y_train_pos_array)\n",
    "y_test_pos = tf.convert_to_tensor(y_test_pos_array)\n",
    "\n",
    "y_train_ner = tf.convert_to_tensor(y_train_ner_array)\n",
    "y_test_ner = tf.convert_to_tensor(y_test_ner_array)\n",
    "\n",
    "y_train_chu = tf.convert_to_tensor(y_train_chu_array)\n",
    "y_test_chu = tf.convert_to_tensor(y_test_chu_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train_pos.shape)\n",
    "print(y_test_pos.shape)\n",
    "\n",
    "print(y_train_ner.shape)\n",
    "print(y_test_ner.shape)\n",
    "\n",
    "print(y_train_chu.shape)\n",
    "print(y_test_chu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_chu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_chu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr = 1e-3)\n",
    "model.compile(optimizer = opt,\n",
    "              loss = {'pos_output': 'categorical_crossentropy', 'ner_output': 'categorical_crossentropy', 'chu_output': 'categorical_crossentropy'},\n",
    "              loss_weights = {'pos_output': 0.2, 'ner_output': 1.0, 'chu_output': 1.0},\n",
    "              metrics = [\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x = x_train,\n",
    "          y = {'pos_output': y_train_pos, 'ner_output': y_train_ner, 'chu_output': y_train_chu},\n",
    "          epochs = 15,\n",
    "          batch_size = 128,\n",
    "          verbose = 1,\n",
    "          validation_data = (x_test, {'pos_output': y_test_pos, 'ner_output': y_test_ner, 'chu_output': y_test_chu})\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/le_pos_classes.npy', le_pos.classes_)\n",
    "np.save('./data/le_ner_classes.npy', le_ner.classes_)\n",
    "np.save('./data/le_chu_classes.npy', le_chu.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype = \"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "end_to_end_model.save(\"./data/fitted_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
