{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Label Encodings and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_pos = preprocessing.LabelEncoder()\n",
    "le_pos.classes_ = np.load('./data/le_pos_classes.npy')\n",
    "\n",
    "le_ner = preprocessing.LabelEncoder()\n",
    "le_ner.classes_ = np.load('./data/le_ner_classes.npy')\n",
    "\n",
    "le_chu = preprocessing.LabelEncoder()\n",
    "le_chu.classes_ = np.load('./data/le_chu_classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./data/fitted_model/\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"Thousands of demonstrators have marched to Narnia for a protest. They are mad at the 4 policies of Sauron that they find objectionable.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_array = input_sentence.split(\" \")\n",
    "for i in string.punctuation:\n",
    "    while(i in sentence_array): \n",
    "        sentence_array.remove(i)\n",
    "sentence_length = len(sentence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos, prob_ner, prob_chu = model.predict(\n",
    "    [[input_sentence]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = logits_to_tokens(prob_pos, le_pos.classes_)\n",
    "ner_list = logits_to_tokens(prob_ner, le_ner.classes_)\n",
    "chu_list = logits_to_tokens(prob_chu, le_chu.classes_)\n",
    "\n",
    "pos_list = pos_list[0][0:sentence_length]\n",
    "ner_list = ner_list[0][0:sentence_length]\n",
    "chu_list = chu_list[0][0:sentence_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {\"CC\": \"Coordinating Conjunction\",\n",
    "            \"CD\": \"Cardinal Number\",\n",
    "            \"DT\": \"Determiner\",\n",
    "            \"EX\": \"Existencial There\",\n",
    "            \"FW\": \"Foreign Word\",\n",
    "            \"IN\": \"Preposition or Subordinating Conjunction\",\n",
    "            \"JJ\": \"Adjective\",\n",
    "            \"JJR\": \"Adjective, Comparative\",\n",
    "            \"JJS\": \"Adjective, Superlative\",\n",
    "            \"LS\": \"List Item Marker\",\n",
    "            \"MD\": \"Modal\",\n",
    "            \"NN\": \"Noun, Singular or Mass\",\n",
    "            \"NNS\": \"Noun, Plural\",\n",
    "            \"NNP\": \"Proper Noun, Singular\",\n",
    "            \"NNPS\": \"Proper Noun, Plural\",\n",
    "            \"PDT\": \"Predeterminer\",\n",
    "            \"POS\": \"Possessive Ending\",\n",
    "            \"PRP\": \"Personal Pronoun\",\n",
    "            \"PRP$\": \"Possessive Pronoun\",\n",
    "            \"RB\": \"Adverb\",\n",
    "            \"RBR\": \"Adverb, Comparative\",\n",
    "            \"RBS\": \"Adverb, Superlative\",\n",
    "            \"RP\": \"Particle\",\n",
    "            \"SYM\": \"Symbol\",\n",
    "            \"TO\": \"To\",\n",
    "            \"UH\": \"Interjection\",\n",
    "            \"VB\": \"Verb, Base Form\",\n",
    "            \"VBD\": \"Verb, Past Tense\",\n",
    "            \"VBG\": \"Verb, Gerund or Present Pariciple\",\n",
    "            \"VBN\": \"Verb, Past Participle\",\n",
    "            \"VBP\": \"Verb, Non-3rd Person Singular Present\",\n",
    "            \"VBZ\": \"Verb, 3rd Person Singular Present\",\n",
    "            \"WDT\": \"Whdeterminer\",\n",
    "            \"WP\": \"Whpronoun\",\n",
    "            \"WP$\": \"Possessive Whpronoun\",\n",
    "            \"WRB\": \"Whadverb\",\n",
    "            \"$\": \"$\",\n",
    "            \"*\": \"*\",\n",
    "            ',': ',', \n",
    "            '.': '.', \n",
    "            ':': ':', \n",
    "            ';': ';',\n",
    "            '``': '``',\n",
    "            'LRB': \"Left Parentheses\",\n",
    "            'RRB': \"Right Parentheses\"}\n",
    "\n",
    "ner_dict = {\"geo\": \"Geographical Entity\",\n",
    "            \"org\": \"Organization\",\n",
    "            \"per\": \"Person\",\n",
    "            \"gpe\": \"Geopolitical Entity\",\n",
    "            \"tim\": \"Time Indicator\",\n",
    "            \"art\": \"Artifact\",\n",
    "            \"eve\": \"Event\",\n",
    "            \"nat\": \"Natural Phenomenon\",\n",
    "            \"O\": \"Not a Named Entity\",\n",
    "            \"*\": \"*\"}\n",
    "\n",
    "chu_dict = {\"B\": \"Begin Chunk\",\n",
    "            \"I\": \"Inside Chunk\",\n",
    "            \"O\": \"Not a Named Entity\",\n",
    "            \"*\": \"*\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Word                           Part-of-Speech  \\\n",
      "0        Thousands                             Noun, Plural   \n",
      "1               of  Prepositon or Subordinating Conjunction   \n",
      "2    demonstrators                             Noun, Plural   \n",
      "3             have    Verb, Non-3rd Person Singular Present   \n",
      "4          marched                    Verb, Past Participle   \n",
      "5               to                                       To   \n",
      "6           Narnia                          Verb, Base Form   \n",
      "7              for  Prepositon or Subordinating Conjunction   \n",
      "8                a                               Determiner   \n",
      "9         protest.                   Noun, Singular or Mass   \n",
      "10            They                         Personal Pronoun   \n",
      "11             are    Verb, Non-3rd Person Singular Present   \n",
      "12             mad                    Verb, Past Participle   \n",
      "13              at  Prepositon or Subordinating Conjunction   \n",
      "14             the                               Determiner   \n",
      "15               4                          Cardinal Number   \n",
      "16        policies                             Noun, Plural   \n",
      "17              of  Prepositon or Subordinating Conjunction   \n",
      "18          Sauron                   Noun, Singular or Mass   \n",
      "19            that  Prepositon or Subordinating Conjunction   \n",
      "20            they                         Personal Pronoun   \n",
      "21            find    Verb, Non-3rd Person Singular Present   \n",
      "22  objectionable.                         Personal Pronoun   \n",
      "\n",
      "          Named Entity Beginning or Inside Chunk  \n",
      "0   Not a Named Entity        Not a Named Entity  \n",
      "1   Not a Named Entity        Not a Named Entity  \n",
      "2   Not a Named Entity        Not a Named Entity  \n",
      "3   Not a Named Entity        Not a Named Entity  \n",
      "4   Not a Named Entity        Not a Named Entity  \n",
      "5   Not a Named Entity        Not a Named Entity  \n",
      "6   Not a Named Entity        Not a Named Entity  \n",
      "7   Not a Named Entity        Not a Named Entity  \n",
      "8   Not a Named Entity        Not a Named Entity  \n",
      "9   Not a Named Entity        Not a Named Entity  \n",
      "10  Not a Named Entity        Not a Named Entity  \n",
      "11  Not a Named Entity        Not a Named Entity  \n",
      "12  Not a Named Entity        Not a Named Entity  \n",
      "13  Not a Named Entity        Not a Named Entity  \n",
      "14  Not a Named Entity        Not a Named Entity  \n",
      "15  Not a Named Entity        Not a Named Entity  \n",
      "16  Not a Named Entity        Not a Named Entity  \n",
      "17  Not a Named Entity        Not a Named Entity  \n",
      "18  Not a Named Entity        Not a Named Entity  \n",
      "19  Not a Named Entity        Not a Named Entity  \n",
      "20  Not a Named Entity        Not a Named Entity  \n",
      "21  Not a Named Entity        Not a Named Entity  \n",
      "22  Not a Named Entity        Not a Named Entity  \n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(0, len(sentence_array))\n",
    "results = pd.DataFrame(columns = [\"-Word-\", \"-Part-of-Speech-\", \"-Named Entity-\", \"-Beginning or Inside Chunk-\"],\n",
    "                       index = indices)\n",
    "for i in results.index:\n",
    "    results.loc[i, \"-Word-\"] = sentence_array[i]\n",
    "    results.loc[i, \"-Part-of-Speech-\"] = pos_dict[pos_list[i]]\n",
    "    results.loc[i, \"-Named Entity-\"] = ner_dict[ner_list[i]]\n",
    "    results.loc[i, \"-Beginning or Inside Chunk-\"] = chu_dict[chu_list[i]]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
